#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitHubçˆ¬è™«æ¼”ç¤ºè„šæœ¬
"""

from github_crawler_simple import GitHubCrawler

def demo():
    """æ¼”ç¤ºGitHubçˆ¬è™«çš„åŸºæœ¬åŠŸèƒ½"""
    print("=== GitHubä»“åº“ä¿¡æ¯çˆ¬è™«æ¼”ç¤º ===\n")
    
    # åˆå§‹åŒ–çˆ¬è™«
    crawler = GitHubCrawler()
    
    # æ¼”ç¤º1: çˆ¬å–å•ä¸ªä»“åº“
    print("1. çˆ¬å–å•ä¸ªä»“åº“ä¿¡æ¯:")
    repo_info = crawler.crawl_repository('microsoft/vscode', include_extra=False)
    
    if repo_info:
        print(f"   ä»“åº“åç§°: {repo_info['name']}")
        print(f"   å®Œæ•´åç§°: {repo_info['full_name']}")
        print(f"   æè¿°: {repo_info['description']}")
        print(f"   ä¸»è¦è¯­è¨€: {repo_info['language']}")
        print(f"   æ˜Ÿæ ‡æ•°: {repo_info['stargazers_count']:,}")
        print(f"   Forkæ•°: {repo_info['forks_count']:,}")
        print(f"   åˆ›å»ºæ—¶é—´: {repo_info['created_at']}")
        print(f"   è®¸å¯è¯: {repo_info['license']}")
        print(f"   ä¸»é¢˜: {', '.join(repo_info['topics'])}")
    
    print("\n" + "="*50 + "\n")
    
    # æ¼”ç¤º2: çˆ¬å–åŒ…å«è¯¦ç»†ä¿¡æ¯çš„ä»“åº“
    print("2. çˆ¬å–åŒ…å«è¯¦ç»†ä¿¡æ¯çš„ä»“åº“:")
    repo_info = crawler.crawl_repository('facebook/react')
    
    if repo_info:
        print(f"   ä»“åº“: {repo_info['full_name']}")
        print(f"   æ˜Ÿæ ‡æ•°: {repo_info['stargazers_count']:,}")
        
        # æ˜¾ç¤ºç¼–ç¨‹è¯­è¨€ç»Ÿè®¡
        if 'languages' in repo_info and repo_info['languages']:
            print("   ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡:")
            languages = repo_info['languages']
            total_bytes = sum(languages.values())
            for lang, bytes_count in list(languages.items())[:3]:  # æ˜¾ç¤ºå‰3ç§è¯­è¨€
                percentage = (bytes_count / total_bytes) * 100
                print(f"     {lang}: {percentage:.1f}%")
        
        # æ˜¾ç¤ºä¸»è¦è´¡çŒ®è€…
        if 'contributors' in repo_info and repo_info['contributors']:
            print("   ä¸»è¦è´¡çŒ®è€…:")
            for contrib in repo_info['contributors'][:3]:  # æ˜¾ç¤ºå‰3ä¸ªè´¡çŒ®è€…
                print(f"     {contrib['login']}: {contrib['contributions']} æ¬¡è´¡çŒ®")
        
        # æ˜¾ç¤ºæœ€æ–°å‘å¸ƒç‰ˆæœ¬
        if 'releases' in repo_info and repo_info['releases']:
            latest_release = repo_info['releases'][0]
            print(f"   æœ€æ–°ç‰ˆæœ¬: {latest_release['tag_name']} ({latest_release['published_at'][:10]})")
    
    print("\n" + "="*50 + "\n")
    
    # æ¼”ç¤º3: æ‰¹é‡çˆ¬å–å¤šä¸ªä»“åº“
    print("3. æ‰¹é‡çˆ¬å–å¤šä¸ªä»“åº“:")
    repo_list = ['microsoft/vscode', 'facebook/react', 'golang/go']
    results = crawler.crawl_multiple_repositories(repo_list, include_extra=False)
    
    print("   çˆ¬å–ç»“æœæ±‡æ€»:")
    for repo in results:
        print(f"   - {repo['full_name']}: {repo['stargazers_count']:,} â­, {repo['forks_count']:,} ğŸ´, {repo['language']}")
    
    # ä¿å­˜ç»“æœ
    print("\n4. ä¿å­˜ç»“æœåˆ°æ–‡ä»¶:")
    crawler.save_to_json(results, 'demo_results.json')
    crawler.save_to_csv(results, 'demo_results.csv')
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
    print("ç”Ÿæˆçš„æ–‡ä»¶: demo_results.json, demo_results.csv")

if __name__ == "__main__":
    demo()